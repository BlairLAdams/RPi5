# Data Quality
Data quality ensures that the data used across your systems is accurate, complete, timely, and consistent. In a water utility, poor data quality can lead to misleading reports, operational delays, or non-compliance.   Field readings may be miskeyed, sensor data may go missing, or asset records might be duplicated — but with clear expectations, monitoring, and stewardship, these issues can be surfaced and corrected before they cause downstream impacts.
Data quality is a continuous discipline — not about perfection, but about making sure the data is good enough to support your decisions and services. Early efforts often focus on understanding known issues, defining quality dimensions, and starting lightweight monitoring for a few critical fields.

## Objective
Establish expectations, ownership, and monitoring for the accuracy and completeness of key datasets that feed operational and analytical processes.

### Key Results
- Define quality rules (e.g., required fields, valid ranges) for three priority datasets  
- Assign data quality stewards or custodians for each dataset  
- Log known quality issues and resolutions in a shared backlog or tracking sheet  
- Set up basic monitoring or alerts for missing/invalid values in one dataset  

## Core Processes
- Rule definition and validation criteria (e.g., no nulls, valid codes)  
- Issue identification, logging, and triage  
- Resolution workflow and ownership handoff  
- Data profiling and exception reporting  
- Quality assurance integration into ETL or ingestion  

## Suggested Metrics
- Percent of records passing defined quality checks  
- Number of open vs resolved quality issues  
- Mean time to resolve a logged data issue  
- Frequency of quality rule violations per table