#!/usr/bin/env python3
# importBronzeWQ.py

"""
This script connects to your PostgreSQL database, ensures the 'bronzeWQ' schema exists,
creates a table named 'waterQuality' within that schema to store water quality data,
and bulk loads data from a CSV file.
The table schema is dynamically generated by inferring column types from the CSV file.
The CSV file is expected at the location: /home/blair/scr/data/waterQuality.csv.
PostgreSQL connection details are prompted with default values.
"""

import os
import sys
import getpass
import pandas as pd
import psycopg2
from psycopg2 import sql

def infer_postgres_type(series):
    """
    Infer a PostgreSQL data type from a pandas Series.
    
    Args:
        series (pandas.Series): The column data.
    
    Returns:
        str: PostgreSQL data type (INTEGER, FLOAT, or TEXT).
    """
    if pd.api.types.is_integer_dtype(series):
        return "INTEGER"
    elif pd.api.types.is_float_dtype(series):
        return "FLOAT"
    else:
        return "TEXT"

def build_create_table_statement(schema_name, table_name, df):
    """
    Build a CREATE TABLE SQL statement using the DataFrame's column definitions.
    
    Args:
        schema_name (str): The target schema name.
        table_name (str): The target table name.
        df (pandas.DataFrame): DataFrame containing the water quality data.
    
    Returns:
        psycopg2.sql.Composed: A composed SQL statement to create the table.
    """
    column_defs = []
    for col in df.columns:
        # Clean up column names by removing spaces, parentheses, and dashes.
        col_clean = col.strip().replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
        pg_type = infer_postgres_type(df[col])
        column_defs.append(sql.SQL("{} {}").format(sql.Identifier(col_clean), sql.SQL(pg_type)))
    
    create_table = sql.SQL("CREATE TABLE IF NOT EXISTS {}.{} ({});").format(
        sql.Identifier(schema_name),
        sql.Identifier(table_name),
        sql.SQL(", ").join(column_defs)
    )
    return create_table

def main():
    # Prompt for PostgreSQL connection details using default values.
    host = input("Enter PostgreSQL host (default 'localhost'): ") or "localhost"
    port_input = input("Enter PostgreSQL port (default 5432): ") or "5432"
    try:
        port = int(port_input)
    except ValueError:
        print("Invalid port number. Using default port 5432.")
        port = 5432
    database = input("Enter PostgreSQL database name (default 'metadb'): ") or "metadb"
    user = input("Enter your PostgreSQL username: ")
    password = getpass.getpass("Enter your PostgreSQL password: ")
    
    # Build connection parameters.
    conn_params = {
        "host": host,
        "port": port,
        "dbname": database,
        "user": user,
        "password": password
    }
    
    # Define the CSV file path.
    CSV_PATH = "/home/blair/scr/data/waterQuality.csv"
    
    # Load the CSV file into a DataFrame to preview and infer the schema.
    try:
        df = pd.read_csv(CSV_PATH)
        print("CSV file loaded successfully. Here's a preview:")
        print(df.head())
    except Exception as e:
        print(f"Error loading CSV file from {CSV_PATH}: {e}")
        sys.exit(1)
        
    # Set the schema and table names for Bronze.
    schema_name = "bronzeWQ"
    table_name = "waterQuality"  # Table name for the CSV data.
    full_table_name = f"{schema_name}.{table_name}"
    
    # Build the CREATE TABLE statement.
    create_table_stmt = build_create_table_statement(schema_name, table_name, df)
    
    try:
        # Connect to PostgreSQL.
        conn = psycopg2.connect(**conn_params)
        cur = conn.cursor()
        print("Connected to PostgreSQL successfully.")
        
        # Ensure the bronzeWQ schema exists.
        cur.execute(sql.SQL("CREATE SCHEMA IF NOT EXISTS {};").format(sql.Identifier(schema_name)))
        print(f"Schema '{schema_name}' is available.")
        
        # Execute the CREATE TABLE statement.
        print("Executing SQL to create table:")
        print(create_table_stmt.as_string(cur))
        cur.execute(create_table_stmt)
        conn.commit()
        print(f"Table '{full_table_name}' created successfully (if it did not already exist).")
        
        # Bulk load CSV data into the table using the COPY command.
        print("Bulk loading data from CSV file into table...")
        # Use explicit quoting so that schema and table names are preserved.
        copy_sql = f'COPY "{schema_name}"."{table_name}" FROM STDIN WITH CSV HEADER DELIMITER \',\''
        with open(CSV_PATH, 'r') as f:
            cur.copy_expert(sql=copy_sql, file=f)
        conn.commit()
        print("Bulk data load completed successfully.")
        
        # Close the database connection.
        cur.close()
        conn.close()
        print("Database connection closed.")
        
    except Exception as e:
        print("An error occurred while executing SQL statements on PostgreSQL:", e)
        sys.exit(1)

if __name__ == '__main__':
    main()
